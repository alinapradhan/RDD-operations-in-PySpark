# ETDS-RDD-
 This notebook demonstrates basic RDD operations using PySpark, including transformations and actions. It serves as a foundational exercise for understanding distributed data processing in Apache Spark
# ETDS 2 Practical 1 - RDD Operations in PySpark

This repository contains the Jupyter Notebook for **Practical 1** of the subject **ETDS 2**, focusing on working with **Resilient Distributed Datasets (RDDs)** using **Apache Spark and PySpark**.

## ğŸ“š Description

The notebook demonstrates the creation, transformation, and actions on RDDs using PySpark. It provides examples of basic RDD operations such as:

- Creating RDDs from data
- Performing transformations (`map`, `filter`, `flatMap`, etc.)
- Actions (`collect`, `count`, `reduce`, etc.)
- Understanding lazy vs eager evaluation
- Combining RDDs

This practical aims to build a foundational understanding of distributed data processing using Spark's low-level API.

## ğŸš€ Technologies Used

- Python 3
- PySpark
- Jupyter Notebook

## ğŸ“ Files

- `ETDS_2_PRACTICAL_1_RDD_.ipynb`: Jupyter Notebook with code and explanations for RDD operations.
- `LICENSE`: MIT License for open-source usage.

## ğŸ”§ Getting Started

1. **Install Dependencies**:
   Make sure PySpark is installed:

   ```bash
   pip install pyspark
